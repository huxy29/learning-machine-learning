# 机器学习基石 hw1

## Problem 1
![][1]

### 适合使用机器学习的三个关键要素：
- 存在某些潜在的模式或者规则可以学习
- 没有具体的定义或者规则，来编写程序，或者不容易给出完备的定义或者规则
- 有大量的可以学习潜在模式或者规则的数据用来学习

### Solution 1
- (i) 判断一个数是否为素数。不需要使用机器学习的方法来做，因为已经有明确的规则可以进行判断：若一个整数只能被1和它本身整除，则为素数，否则不是素数；
- (ii) 检测信用卡消费中的潜在欺诈行为。属于使用机器学习中检测异常点检测问题；
- (iii) 确定物体下落所需的时间。不需要使用机器学习，因为有物理公式可以计算；
- (iv) 确定繁忙路口的交通信号灯的最佳周期。可以统计不同路口交通信号灯的周期和拥堵程度的数据，然后使用回归分析，学习信号灯周期与拥堵程度的之间的关系；
- (v) 确定建议进行特定医疗检查的年龄。可以对不同年龄人群生病情况进行统计，进行聚类分析，年龄相似患病相似的人群聚为一类，就可以向这个年龄附近的人推荐相应的医疗检查；

## Problem 2-5

![][2]

### 机器学习分类
- 监督式学习：训练数据由一条记录的输入特征和预期输出组成，希望通过训练学习到潜在的模式，来预测未知的数据，包括分类和回归
- 无监督学习：与监督式学习不同的是训练数据中不包含预期的输出，希望机器自动通过输入特征学习到潜在的模式，典型的如聚类
- 主动学习：是半监督机器学习的一个特例，在主动学习中，一个学习算法可以交互式的询问用户（或其他信息源）来获得在新的数据点所期望的输出
- 强化学习：强调如何基于环境而行动，以取得最大化的预期利益，每次做出一个决策，都会得到一定的回馈，或正向的，或负向的，基于回馈，做出相应的调整，优化下一次的决策

### Solution 2-5
2. 采用不同的策略下棋，以结果作为回馈，学习更好的下棋策略，应该使用强化学习
3. 不给定主题对书籍进行分类，属于无监督学习，可以使用聚类分析
4. 人脸识别，训练数据为一堆图像，并带有正确的标注是否为人脸，属于监督式学习
5. 有选择性的安排实验，来快速的评估抗癌药物的效果，类似主动学习，对每一种药物，由于不知道实际效果，于是进行小白鼠实验，来获得输出

## Problem 6-8
![][3]

### Solution 6-8
6. f 对任何输入都输出 +1，g 对偶数下标的样本输出 -1，所以只需要判断 N+1 到 N+L 中有多少个偶数即可，可以分不同情况讨论：若 L 为偶数，则肯定有 L/2 个偶数；若 L 为奇数，N+1 也为奇数，则奇数占多数，故有 (L-1)/2 个偶数；若 L 为奇数，N+1 为偶数，则偶数占多数，故有 (L+1)/2 个偶数。最后可整理为一个式子 1/L * ([(N+L)/2] - [N/2])，(中括号表示向下取整)
7. 题目意思是 f 在训练集上完全正确，则有多少种不同的 f，由于测试集上的每一个样本都有两种可能输出，所以不同的 f 有 2^L 种
8. 未完全理解

## Problem 9-12
![][4]

### Solution 9-12
&emsp;&emsp;从罐子中随机抓取一个小球为橘色的概率为 u，现从中随机抓取10个小球，橘色小球个数为 10v

9. 随机抓取的10个小球中有5个是橘色的概率：`C(10, 5) * 0.5^5 * 0.5^5 = 63/256`
10. 随机抓取的10个小球中有9个是橘色的概率：`C(10, 9) * 0.9^9 * 0.1^1 = 0.9^9`
11. 随机抓取的10个小球中橘色小球个数不大于1的概率：`C(10, 1) * 0.9^1 * 0.1^9 + 0.1^10 = 9.1e-9`
12. `u=0.9, v<=0.1 => |u-v|>=0.8, epsilon=0.8`， 由Hoeffding不等式 `P(|u-v|>=epsilon) <= 2 * exp(-2 * N * epsilon^2) `，带入计算得 `5.5215e-6`

## Problem 13-14
![][5]

### Solution 13-14
13. AC两种骰子的1是橘色的，因此随机抽取到1个骰子是橘色1的概率为 0.5，所以抽取到5个橘色1的概率为 0.5^5
14. 分析可知，AB两种骰子完全相反，CD两种骰子也是完全相反，所以要想抽到的骰子中存在某一点数是都是同一个颜色，那么就不能有两种以上的骰子的组合。最简单的，只抽到一种骰子，那肯定符合题意，抽到两种骰子，那么不能是AB，也不能是CD，这样一来可能的组合为：A、B、C、D、AC、AD、BC、BD，它们的概率都可以求出来，前四种的概率都相等，为 `0.25^5`，后四种的也都相等，为 `( C(5,1) + C(5,2) + C(5,3) + C(5,4) )* 0.25^5`

## Problem 15-20
&emsp;&emsp;由于 15-20 都是 PLA 的实现，大部分代码都是可以共用的，因此放在同一个类 `PLA` (pla.py) 中。读数据的方法 `read_file` 将 X 读入 numpy 矩阵，并且为了方便计算，按照题目中的建议，在 X 矩阵第一列之前添加了一列 1，将类标签 y 也读入一个 numpy 数组中，最后返回 X 和 y 。

&emsp;&emsp;直接使用默认参数调用 `train` 方法可以解答 T15，设置 'random=True' 的 `train` 方法可以解答 T16，同时设置 'random=True' 和 'eta=0.5' 可以解答 T17；

&emsp;&emsp;`train_pocket` 方法在 `train` 方法的基础上加入 'w_pocket'，将最优的 w 装入口袋(pocket)，实现了 pocket 算法，T18 调用 `train_pocket` 和 `verify_pocket` 方法 2000 次，统计平均错误率，具体运行的代码在 `pla.ipynb` 中; T19 调用 `train_pocket` 和 设置了 'pocket=False' 的 `verify_pocket` 方法 2000 次，统计平均错误率，因为在 `train` 方法中，同时保存了迭代50轮后的 w 和 w_pocket，设置 'pocket=False' 时是使用 w 来在测试集上做分类的；T20 在 T18 的基础上设置 'iteration=100' 即可。


**【注：如有错误，望不吝指正，欢迎交流学习。邮箱：3051266672@qq.com】**

---

## 参考
- http://blog.csdn.net/a1015553840/article/details/50986313
- http://blog.csdn.net/a1015553840/article/details/50979434
- http://blog.csdn.net/a1015553840/article/details/50979640

  [1]: https://github.com/huxy29/learning-machine-learning/blob/master/machine-learning-foundations/hw1/screenshot/1.png
  [2]: https://github.com/huxy29/learning-machine-learning/blob/master/machine-learning-foundations/hw1/screenshot/2-5.png
  [3]: https://github.com/huxy29/learning-machine-learning/blob/master/machine-learning-foundations/hw1/screenshot/6-8.png
  [4]: https://github.com/huxy29/learning-machine-learning/blob/master/machine-learning-foundations/hw1/screenshot/9-12.png
  [5]: https://github.com/huxy29/learning-machine-learning/blob/master/machine-learning-foundations/hw1/screenshot/13-14.png
